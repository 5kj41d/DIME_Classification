{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f4a2dbe-dfdc-4f91-8e8d-6c59443292c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import os \n",
    "from torchvision.io import read_image\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torchvision.utils as vutils\n",
    "import matplotlib.animation as animation\n",
    "from IPython.display import HTML\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.optim import Adam\n",
    "import glob\n",
    "import json\n",
    "# from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef6e5007-d472-4aa6-ba45-5efb3d25cf70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Root directory for dataset\n",
    "root_dir = r'/run/media/magnusjsc/T7/Classification-and-3D-reconstruction-of-archaeological-artifacts_DATA/Splitted data by era - GAN project/test_iron'\n",
    "res_dir = r'results/gan_results'\n",
    "\n",
    "# Number of workers for dataloader. (4 * nr_gpus)\n",
    "workers = (4 * 1)\n",
    "\n",
    "# Spatial size of training images. All images will be resized to this size, using a transformer.\n",
    "image_size = 64\n",
    "\n",
    "# Beta1 hyperparameter for Adam optimizers\n",
    "beta1 = 0.5\n",
    "\n",
    "# RGB\n",
    "n_channels = 3 \n",
    "\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1\n",
    "\n",
    "# Decide which device we want to run on\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "703866ef-ef7e-4d5d-a754-51dd23d80704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Add image interpolation for sharper images \n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),  # Resize images to 64x64\n",
    "    transforms.ToTensor(),           # Convert images to PyTorch tensors\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), # [-1,1] for each channel -> input[channel]=(input[channel]âˆ’mean[channel])/std[channel]\n",
    "])\n",
    "\n",
    "dataset = ImageFolder(root = root_dir, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ba1ed29-5822-4568-8cc7-4532f7fa5d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize weights\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02) # Mean 0, STD 0.2\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "        \n",
    "class D(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            ndf, \n",
    "            ngpu\n",
    "        ):\n",
    "        super(D, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        ndf = ndf \n",
    "    \n",
    "        self.main = nn.Sequential(\n",
    "            # Input is (n_channels) x 128 x 128\n",
    "            nn.Conv2d(n_channels, ndf, 4, 2, 1, bias = False),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "            # State size. (ndf) x 64 x 64\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias = False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "            # State size. (ndf*2) x 32 x 32\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias = False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "            # State size. (ndf*4) x 16 x 16\n",
    "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias = False),\n",
    "            nn.BatchNorm2d(ndf * 8),\n",
    "            nn.LeakyReLU(0.2, inplace = True),\n",
    "            # State size. (ndf*8) x 8 x 8\n",
    "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias = False),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.main(x) # Output size = 1x1 \n",
    "        return x \n",
    "\n",
    "\n",
    "\n",
    "class G(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        nz, \n",
    "        ngf,\n",
    "        ngpu\n",
    "    ): \n",
    "        super(G, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "\n",
    "        latent_size = nz\n",
    "        ngf = ngf\n",
    "        \n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            # state size. ``(ngf*8) x 4 x 4``\n",
    "            nn.ConvTranspose2d(latent_size, ngf * 8, kernel_size = 4, stride = 1, padding = 0, bias = False),\n",
    "            nn.BatchNorm2d(ngf * 8),\n",
    "            nn.ReLU(inplace = True),\n",
    "            # state size. ``(ngf*4) x 8 x 8``\n",
    "            nn.ConvTranspose2d(ngf * 8, ngf * 4, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(inplace = True),\n",
    "            # state size. ``(ngf*2) x 16 x 16``\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(inplace = True),\n",
    "            # state size. ``(ngf) x 32 x 32``\n",
    "            nn.ConvTranspose2d(ngf * 2, ngf, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(inplace = True),\n",
    "            # state size. ``(nc) x 64 x 64``\n",
    "            # Adding one more layer to upscale from 64x64 to 128x128\n",
    "            nn.ConvTranspose2d(ngf, n_channels, kernel_size = 4, stride = 2, padding = 1, bias = False),\n",
    "            nn.Tanh()\n",
    "            # state size. ``(nc) x 128 x 128``\n",
    "        )        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.main(x) # Output size = 64x64 \n",
    "        return x \n",
    "\n",
    "\n",
    "# Generate summaries:\n",
    "# discriminator = D(hyperparams = {'ndf': 64})  \n",
    "# generator = G(hyperparams = {'nz': 100, 'ngf': 64})  \n",
    "\n",
    "# discriminator_summary = summary(discriminator, input_size = (25, 3, 128, 128))\n",
    "# generator_summary = summary(generator, input_size = (25, 100, 1, 1))\n",
    "\n",
    "# Print summaries\n",
    "# print(\"Discriminator Summary:\")\n",
    "# print(discriminator_summary)\n",
    "\n",
    "# print(\"\\nGenerator Summary:\")\n",
    "# print(generator_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5075a5f-0c5b-4f35-ac38-ce10d4535658",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"checkpoints\"\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "def save_checkpoint(g_model, d_model, optimizer_g, optimizer_d):\n",
    "    checkpoint_path = os.path.join(checkpoint_dir, f\"gan_checkpoint.pt\")\n",
    "    torch.save({\n",
    "        'generator_state_dict': g_model.state_dict(),\n",
    "        'discriminator_state_dict': d_model.state_dict(),\n",
    "        'optimizer_g_state_dict': optimizer_g.state_dict(),\n",
    "        'optimizer_d_state_dict': optimizer_d.state_dict()\n",
    "    }, checkpoint_path)\n",
    "\n",
    "def load_checkpoint(checkpoint_path):\n",
    "    checkpoints = torch.load(checkpoint_path)\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    generator_state_dict = checkpoint['generator_state_dict']\n",
    "    discriminator_state_dict = checkpoint['discriminator_state_dict']\n",
    "    optimizer_g_state_dict = checkpoint['optimizer_g_state_dict']\n",
    "    optimizer_d_state_dict = checkpoint['optimizer_d_state_dict']\n",
    "\n",
    "    return generator_state_dict, discriminator_state_dict, optimizer_g_state_dict, optimizer_d_state_dict\n",
    "\n",
    "\n",
    "def find_latest_checkpoint():\n",
    "    checkpoints = glob.glob(os.path.join(checkpoint_dir, \"gan_checkpoint.pt\"))\n",
    "    if checkpoints: \n",
    "        # Use the OS metadata to recognize the latest file changed/added\n",
    "        latest_checkpoint = max(checkpoints, key = os.path.getctime)\n",
    "        return latest_checkpoint\n",
    "    else: \n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35f4dd2a-e4ca-4c6f-96dd-1e986a5b5dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint was found! Setting model and optimizer states\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 120\u001b[0m\n\u001b[1;32m    118\u001b[0m errD_fake \u001b[38;5;241m=\u001b[39m criterion(output, label)\n\u001b[1;32m    119\u001b[0m errD_fake\u001b[38;5;241m.\u001b[39mbackward() \n\u001b[0;32m--> 120\u001b[0m D_G_z1 \u001b[38;5;241m=\u001b[39m \u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Compute the total error for the discriminator over real and fake runs \u001b[39;00m\n\u001b[1;32m    122\u001b[0m errD \u001b[38;5;241m=\u001b[39m errD_real \u001b[38;5;241m+\u001b[39m errD_fake \n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "real_label = 1 \n",
    "fake_label = 0 \n",
    "n_epochs = 1000 \n",
    "start_epoch = 0\n",
    "latest_checkpoint = None \n",
    "g_state_dict = None \n",
    "d_state_dict = None \n",
    "optimizer_g_state_dict = None\n",
    "optimizer_d_state_dict = None\n",
    "\n",
    "img_list = [] \n",
    "\n",
    "# Hyperparams \n",
    "lr = 0.0005 \n",
    "nz = 100 \n",
    "ngf = 32\n",
    "ndf = 70 \n",
    "batch_size = 128 \n",
    "\n",
    "# Init models \n",
    "d_model = D(ndf = ndf, ngpu = ngpu).to(device)\n",
    "g_model = G(ngf = ngf, ngpu = ngpu, nz = nz).to(device)\n",
    "\n",
    "# Optimizers \n",
    "optimizer_d = Adam(d_model.parameters(), lr = lr, betas = (0.5, 0.999))\n",
    "optimizer_g = Adam(g_model.parameters(), lr = lr, betas = (0.5, 0.999))\n",
    "\n",
    "# Loss function \n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Look for checkpoint \n",
    "checkpoint = find_latest_checkpoint()\n",
    "if checkpoint: \n",
    "    print(\"Checkpoint was found! Setting model and optimizer states\")\n",
    "    g_state_dict_load, d_state_dict_load, optimizer_g_state_dict_load, optimizer_d_state_dict_load = load_checkpoint(checkpoint)\n",
    "    g_model.load_state_dict(g_state_dict_load)\n",
    "    d_model.load_state_dict(d_state_dict_load)\n",
    "    optimizer_g.load_state_dict(optimizer_g_state_dict_load)\n",
    "    optimizer_d.load_state_dict(optimizer_d_state_dict_load)\n",
    "else: \n",
    "    g_model.apply(weights_init)\n",
    "    d_model.apply(weights_init)\n",
    "\n",
    "# Handle multi-GPU if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    g_model = nn.DataParallel(g_model, list(range(ngpu)))\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    d_model = nn.DataParallel(d_model, list(range(ngpu)))\n",
    "\n",
    "losses_file_path = os.path.join(res_dir, 'losses.txt')\n",
    "# Check if the losses file already exists    \n",
    "if not os.path.exists(losses_file_path):\n",
    "    with open(losses_file_path, 'w') as f:\n",
    "        f.write(\"\")\n",
    "else: \n",
    "    with open(losses_file_path, 'r') as f:\n",
    "        lines = f.readlines() \n",
    "        # Update current epoch\n",
    "        if lines:\n",
    "            last_line = lines[-1]\n",
    "            parts = last_line.split(' - ')\n",
    "            # Set start epoch if found \n",
    "            start_epoch = int(parts[0])\n",
    "\n",
    "# Fresh dataloader\n",
    "data_loader = DataLoader(\n",
    "    dataset, \n",
    "    batch_size = batch_size, \n",
    "    shuffle = True,\n",
    "    num_workers = workers # Parallel workers\n",
    ")\n",
    "\n",
    "# Used for showing the progression of G\n",
    "# Number of fake images made is 64\n",
    "fixed_noise = torch.randn(64, nz, 1, 1, device = device) \n",
    "\n",
    "# Training \n",
    "for epoch in range(start_epoch, n_epochs):\n",
    "    D_losses = []\n",
    "    G_losses = []\n",
    "    img_list = []\n",
    "    avg_loss_G = []\n",
    "    avg_loss_D = [] \n",
    "\n",
    "    # Epoch folder\n",
    "    epoch_dir = os.path.join(res_dir, f\"epoch_{epoch}\")\n",
    "    if not os.path.exists(epoch_dir):\n",
    "        os.makedirs(epoch_dir)\n",
    "    \n",
    "    # Save model states every 5 epoch\n",
    "    if epoch % 5 == 0: \n",
    "        save_checkpoint(\n",
    "            g_model = g_model, \n",
    "            d_model = d_model, \n",
    "            optimizer_g = optimizer_g, \n",
    "            optimizer_d = optimizer_d\n",
    "        )\n",
    "    \n",
    "    for i, data in enumerate(data_loader, 0):\n",
    "        # Train discriminator with real images:\n",
    "        d_model.zero_grad() \n",
    "        real_device = data[0].to(device)\n",
    "        b_size = real_device.size(0)\n",
    "        # Fill the batch with real_labels i.e. 1\n",
    "        label = torch.full((b_size,), real_label, dtype = torch.float, device = device) \n",
    "        # Forward \n",
    "        output = d_model(real_device).view(-1)\n",
    "    \n",
    "        errD_real = criterion(output, label)\n",
    "        errD_real.backward()\n",
    "        # Calc mean loss over whole batch\n",
    "        D_x = output.mean().item()\n",
    "        \n",
    "        latent = torch.randn(b_size, nz, 1, 1, device = device) \n",
    "        fake = g_model(latent) \n",
    "        label.fill_(fake_label) \n",
    "        output = d_model(fake.detach()).view(-1) \n",
    "        errD_fake = criterion(output, label)\n",
    "        errD_fake.backward() \n",
    "        D_G_z1 = output.mean().item()\n",
    "        # Compute the total error for the discriminator over real and fake runs \n",
    "        errD = errD_real + errD_fake \n",
    "        optimizer_d.step()\n",
    "    \n",
    "        # Save a batch of generated images at the end of each epoch - Quality check\n",
    "        if epoch == n_epochs - 1:\n",
    "            with torch.no_grad():\n",
    "                fake_images = g_model(latent).detach().cpu()  \n",
    "            # Save each image in the batch individually\n",
    "            for j, img in enumerate(fake_images):\n",
    "                img_filename = os.path.join(epoch_dir, f'generated_image_{epoch}_{i}_{j}.png')\n",
    "                vutils.save_image(img, img_filename, normalize = True)\n",
    "    \n",
    "        # Train the generator \n",
    "        g_model.zero_grad() \n",
    "        label.fill_(real_label) # fake labels are real for generator cost\n",
    "        output = d_model(fake).view(-1) # Since we just updated D, perform another forward pass of all-fake batch through D (d_model)\n",
    "        errG = criterion(output, label) # Calculate G's loss based on this output\n",
    "        errG.backward()\n",
    "        D_G_z2 = output.mean().item() # Same as (D_G_z1 -> D(G(z1))) - The output loss on fake images made by the generator. Training\n",
    "        optimizer_g.step()\n",
    "        \n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "    \n",
    "        if (i == len(data_loader) - 1):\n",
    "            with torch.no_grad():\n",
    "                # Number of fake images generated depends on the fixed noise vector\n",
    "                fake = g_model(fixed_noise).detach().cpu()\n",
    "            img_list.append(vutils.make_grid(fake, padding = 2, normalize = True))\n",
    "    \n",
    "    # Calculate mean loss for the epoch\n",
    "    avg_loss_G_epoch = np.mean(G_losses)\n",
    "    avg_loss_D_epoch = np.mean(D_losses)\n",
    "    \n",
    "    # Save losses to a file\n",
    "    with open(os.path.join(res_dir, 'losses.txt'), 'a') as f:\n",
    "        f.write(f\"{epoch} - {avg_loss_G_epoch} : {avg_loss_D_epoch}\\n\")\n",
    "    \n",
    "    for i, img_grid in enumerate(img_list):\n",
    "        filename = os.path.join(epoch_dir, f'generated_images_epoch_{i}.png')\n",
    "        vutils.save_image(img_grid, filename) \n",
    "    \n",
    "# Plot and save the losses graph\n",
    "epochs = []\n",
    "generator_losses = []\n",
    "discriminator_losses = []\n",
    "with open(os.path.join(trial_dir, 'losses.txt'), 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines: \n",
    "        parts = line.strip().split(' - ')\n",
    "        epoch = int(parts[0])\n",
    "        losses = parts[1].split(' : ')\n",
    "        generator_loss = float(losses[0])\n",
    "        discriminator_loss = float(losses[1])\n",
    "\n",
    "        epochs.append(epoch)\n",
    "        generator_losses.append(generator_loss)\n",
    "        discriminator_losses.append(discriminator_loss)\n",
    "    \n",
    "# Plot and save the losses graph\n",
    "plt.figure(figsize = (10, 5))\n",
    "plt.plot(epochs, generator_losses, label = 'Generator Loss')\n",
    "plt.plot(epochs, discriminator_losses, label = 'Discriminator Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Generator and Discriminator Losses across Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(os.path.join(trial_dir, 'epoch_losses_graph.png'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8644b4-e149-43ae-8dc1-d5cfb0d05a41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
