{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ddfa3d5-4ab2-469e-b1dd-a1b89456403b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "import os \n",
    "from torchinfo import summary\n",
    "from torchvision.io import read_image\n",
    "from torch.utils.data import random_split\n",
    "import time \n",
    "import random # Random Search \n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ccd4629-ca16-429d-abf9-e7391020fbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = \"/run/media/magnusjsc/T7/Classification-and-3D-reconstruction-of-archaeological-artifacts_DATA/DIME images\"\n",
    "\n",
    "def load_data_from_directory(directory_path, label, limit = 10000):\n",
    "    data = []\n",
    "    labels = []\n",
    "    count = 0 \n",
    "\n",
    "    for filename in os.listdir(directory_path):\n",
    "        if filename.endswith(\".jpg\"):\n",
    "            image_path = os.path.join(directory_path, filename)\n",
    "            image = read_image(image_path)\n",
    "\n",
    "            # Check if image is RGB\n",
    "            if image.shape[0] == 3: \n",
    "                data.append(image)\n",
    "                labels.append(label)\n",
    "                count += 1 \n",
    "\n",
    "            if count >= limit: \n",
    "                break; \n",
    "\n",
    "    return data, labels # Tuple \n",
    "\n",
    "# Load the data \n",
    "data, labels = load_data_from_directory(\n",
    "    path_to_data,\n",
    "    label = 0, # CHANGE\n",
    "    limit = 25 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42ea41f3-82f7-420b-895c-616371aaae56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of training set: 18, validation set: 4, testing set: 3\n"
     ]
    }
   ],
   "source": [
    "imgTrans = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Resize(size = (224,224))\n",
    "    ]\n",
    ")\n",
    "\n",
    "training = 0.7\n",
    "validation = 0.15\n",
    "testing = 0.15 \n",
    "\n",
    "# TODO: MISSING LABELS\n",
    "train_set, val_set, test_set = random_split(data, [training, validation, testing]) # Partition the dataset\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "train_loader = DataLoader(train_set, batch_size = batch_size, shuffle = True)\n",
    "val_loader = DataLoader(val_set, batch_size = batch_size, shuffle = False)\n",
    "test_loader = DataLoader(test_set, batch_size = batch_size, shuffle = False) \n",
    "\n",
    "print(f'Length of training set: {len(train_set)}, validation set: {len(val_set)}, testing set: {len(test_set)}')\n",
    "\n",
    "n_channels = 3\n",
    "n_classes = 1 # TODO: Calculate number of distinct classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05fa9650-fe1a-4fcb-b957-c300911673cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x torch.Size([64, 12, 27, 27])\n",
      "Size of x before fc torch.Size([64, 8748])\n",
      "=====================================================================================================================================================================\n",
      "Layer (type:depth-idx)                   Input Shape               Param #                   Output Shape              Mult-Adds                 Trainable\n",
      "=====================================================================================================================================================================\n",
      "CNN                                      [64, 3, 224, 224]         --                        [64, 1]                   --                        True\n",
      "├─ModuleList: 1-1                        --                        --                        --                        --                        True\n",
      "│    └─0.weight                                                    ├─864\n",
      "│    └─0.bias                                                      ├─32\n",
      "│    └─3.weight                                                    ├─4,608\n",
      "│    └─3.bias                                                      ├─16\n",
      "│    └─6.weight                                                    ├─768\n",
      "│    └─6.bias                                                      └─12\n",
      "│    └─Conv2d: 2-1                       [64, 3, 224, 224]         896                       [64, 32, 222, 222]        2,826,141,696             True\n",
      "│    │    └─weight                                                 ├─864\n",
      "│    │    └─bias                                                   └─32\n",
      "│    └─ReLU: 2-2                         [64, 32, 222, 222]        --                        [64, 32, 222, 222]        --                        --\n",
      "│    └─MaxPool2d: 2-3                    [64, 32, 222, 222]        --                        [64, 32, 111, 111]        --                        --\n",
      "│    └─Conv2d: 2-4                       [64, 32, 111, 111]        4,624                     [64, 16, 111, 111]        3,646,227,456             True\n",
      "│    │    └─weight                                                 ├─4,608\n",
      "│    │    └─bias                                                   └─16\n",
      "│    └─ReLU: 2-5                         [64, 16, 111, 111]        --                        [64, 16, 111, 111]        --                        --\n",
      "│    └─MaxPool2d: 2-6                    [64, 16, 111, 111]        --                        [64, 16, 55, 55]          --                        --\n",
      "│    └─Conv2d: 2-7                       [64, 16, 55, 55]          780                       [64, 12, 54, 54]          145,566,720               True\n",
      "│    │    └─weight                                                 ├─768\n",
      "│    │    └─bias                                                   └─12\n",
      "│    └─ReLU: 2-8                         [64, 12, 54, 54]          --                        [64, 12, 54, 54]          --                        --\n",
      "│    └─MaxPool2d: 2-9                    [64, 12, 54, 54]          --                        [64, 12, 27, 27]          --                        --\n",
      "├─Linear: 1-2                            [64, 8748]                8,749                     [64, 1]                   559,936                   True\n",
      "│    └─weight                                                      ├─8,748\n",
      "│    └─bias                                                        └─1\n",
      "=====================================================================================================================================================================\n",
      "Total params: 15,049\n",
      "Trainable params: 15,049\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (Units.GIGABYTES): 6.62\n",
      "=====================================================================================================================================================================\n",
      "Input size (MB): 38.54\n",
      "Forward/backward pass size (MB): 926.32\n",
      "Params size (MB): 0.06\n",
      "Estimated Total Size (MB): 964.91\n",
      "=====================================================================================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nNote: A kernel with size 3x3 and a stride of 1 preserves the spatial dimension of the image.\\n'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classifier  \n",
    "class CNN(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_layers: int,\n",
    "        hyperparams: dict \n",
    "    ):\n",
    "        super(CNN, self).__init__()\n",
    "\n",
    "        self.num_layers = num_layers\n",
    "        self.layers = nn.ModuleList() \n",
    "        final_channel = 0\n",
    "        final_kernel = 0\n",
    "        final_padding = 0\n",
    "        final_stride = 0\n",
    "\n",
    "        for i in range(num_layers):\n",
    "            in_channels = n_channels if i == 0 else hyperparams['out_channels'][i - 1] \n",
    "            out_channels = hyperparams['out_channels'][i]\n",
    "            kernel_size = hyperparams['kernel_size'][i]\n",
    "            stride = hyperparams['stride'][i]\n",
    "            padding = hyperparams['padding'][i]\n",
    "            self.layers.append(\n",
    "                nn.Conv2d(\n",
    "                    in_channels = in_channels,\n",
    "                    out_channels = out_channels,\n",
    "                    kernel_size = kernel_size,\n",
    "                    padding = padding\n",
    "                )\n",
    "            )\n",
    "            self.layers.append(nn.ReLU())\n",
    "            self.layers.append(\n",
    "                nn.MaxPool2d(\n",
    "                    kernel_size = 2,\n",
    "                    stride = 2\n",
    "                )\n",
    "            )\n",
    "            final_channel = out_channels\n",
    "            final_kernel = kernel_size\n",
    "            final_stride = stride\n",
    "            final_padding = padding\n",
    "\n",
    "        # TODO: FIX THE CALCULATION OF THE IMAGE SIZE FROM 224x224 to THE LAST OUTPUT FROM THE CONV LAYER - 224->28 \n",
    "        \n",
    "        # FC input size - Last i \n",
    "        input_size = ((28 - final_kernel + 2 * final_padding) // final_stride) + 1\n",
    "        fc_input_size = final_channel * (input_size ** 2)\n",
    "        \n",
    "        self.fc = nn.Linear(fc_input_size, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        print(f'Shape of x {x.shape}')\n",
    "        x = x.view(x.size(0), -1) # Flatten\n",
    "        print(f'Size of x before fc {x.shape}')\n",
    "        x = self.fc(x)\n",
    "        return x \n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss() \n",
    "\n",
    "hyperparams_test = {\n",
    "    'learning_rate': 0.1,\n",
    "    'batch_size': 64,\n",
    "    'num_epochs': 30,\n",
    "    'num_layers': 3,\n",
    "    'out_channels': [32, 16, 12],\n",
    "    'kernel_size': [3, 3, 2],\n",
    "    'padding': [0, 1, 0],\n",
    "    'stride': [3, 2, 1]\n",
    "    # TODO: Add more! \n",
    "}\n",
    "\n",
    "cnn_model = CNN(\n",
    "    num_layers = hyperparams_test['num_layers'],\n",
    "    hyperparams = hyperparams_test\n",
    ")\n",
    "\n",
    "optimizer = Adam(cnn_model.parameters(), lr = hyperparams_test['learning_rate'])\n",
    "\n",
    "summary(\n",
    "    cnn_model,\n",
    "    input_size = (hyperparams_test['batch_size'], 3, 224, 224), \n",
    "    verbose = 2, \n",
    "    col_names = [\n",
    "        \"input_size\", \n",
    "        \"num_params\", \n",
    "        \"output_size\", \n",
    "        \"mult_adds\", \n",
    "        \"trainable\"\n",
    "    ],\n",
    "    mode = 'train'\n",
    ")\n",
    "\n",
    "'''\n",
    "Note: A kernel with size 3x3 and a stride of 1 preserves the spatial dimension of the image.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b42c7d-76c8-4977-be77-d8929f7dd844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training, validation and testing loop \n",
    "\n",
    "# TODO !!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d12418b-a805-4406-8ce8-798522203903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Search for hyperparameter search\n",
    "hyperparams = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'batch_size': [16, 32, 64],\n",
    "    'num_epochs': [30, 90, 120],\n",
    "    'num_layers': [2, 3, 4, 5],\n",
    "    'layer_out': [32, 64, 128],\n",
    "    'kernel_size': [2, 3, 4, 5],\n",
    "    'padding': [0, 1, 2]\n",
    "    # TODO: Add more! \n",
    "}\n",
    "\n",
    "trails = 10 \n",
    "\n",
    "best_accuracy = 0\n",
    "best_hyperparams = None\n",
    "\n",
    "# TODO: Finish random search function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a356db-d100-43c6-b13f-f5803b685b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
